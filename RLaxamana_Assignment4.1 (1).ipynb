{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-2/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "42b5e80b-ad1d-4335-a1f7-10a91127e3dc"
    }
   },
   "source": [
    "_**Use SageMaker's XGBoost to train a binary classification model and for a list of tumors in batch file, predict if each is malignant**_\n",
    "\n",
    "_**It also shows how to use the input output joining / filter feature in Batch transform in details**_\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Background\n",
    "This purpose of this notebook is to train a model using SageMaker's XGBoost and UCI's breast cancer diagnostic data set to illustrate at how to run batch inferences and how to use the Batch Transform I/O join feature. UCI's breast cancer diagnostic data set is available at https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29. The data set is also available on Kaggle at https://www.kaggle.com/uciml/breast-cancer-wisconsin-data. The purpose here is to use this data set to build a predictve model of whether a breast mass image indicates benign or malignant tumor. \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "* The SageMaker role arn used to give training and batch transform access to your data. The snippet below will use the same role used by your SageMaker notebook instance. Otherwise, specify the full ARN of a role with the SageMakerFullAccess policy attached.\n",
    "* The S3 bucket that you want to use for training and storing model objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (2.215.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.232.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (23.2.0)\n",
      "Collecting boto3<2.0,>=1.34.142 (from sagemaker)\n",
      "  Downloading boto3-1.35.49-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.1.3)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.21.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (23.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.2)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.3.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.1.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.31.0)\n",
      "Collecting sagemaker-core<2.0.0,>=1.0.0 (from sagemaker)\n",
      "  Downloading sagemaker_core-1.0.10-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting sagemaker-mlflow (from sagemaker)\n",
      "  Downloading sagemaker_mlflow-0.1.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (3.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.66.1)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Collecting botocore<1.36.0,>=1.35.49 (from boto3<2.0,>=1.34.142->sagemaker)\n",
      "  Downloading botocore-1.35.49-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.34.142->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.34.142->sagemaker) (0.10.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.17.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker) (2.7.0)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker) (13.7.1)\n",
      "Collecting mock<5.0,>4.0 (from sagemaker-core<2.0.0,>=1.0.0->sagemaker)\n",
      "  Downloading mock-4.0.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from docker->sagemaker) (1.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (2024.2.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.16)\n",
      "Collecting mlflow>=2.8 (from sagemaker-mlflow->sagemaker)\n",
      "  Downloading mlflow-2.17.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Collecting mlflow-skinny==2.17.1 (from mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading mlflow_skinny-2.17.1-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: Flask<4 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker) (2.3.3)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting graphene<4 (from mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading graphene-3.4-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker) (3.6)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker) (3.8.4)\n",
      "Requirement already satisfied: pyarrow<18,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker) (15.0.2)\n",
      "Requirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker) (1.4.2)\n",
      "Requirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker) (1.13.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker) (2.0.29)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker) (3.1.3)\n",
      "Collecting gunicorn<24 (from mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker) (8.1.7)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading databricks_sdk-0.36.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker) (0.4.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (2.17.2)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: Werkzeug>=2.3.7 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker) (2.3.8)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker) (2.1.2)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker) (1.7.0)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow>=2.8->sagemaker-mlflow->sagemaker) (2.1.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker) (3.1.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow->sagemaker) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow->sagemaker) (3.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.8->sagemaker-mlflow->sagemaker) (3.0.3)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker) (1.16.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker) (4.7.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow>=2.8->sagemaker-mlflow->sagemaker) (0.6.0)\n",
      "Downloading sagemaker-2.232.2-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.35.49-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sagemaker_core-1.0.10-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.4/388.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sagemaker_mlflow-0.1.0-py3-none-any.whl (24 kB)\n",
      "Downloading botocore-1.35.49-py3-none-any.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow-2.17.1-py3-none-any.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-2.17.1-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Downloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphene-3.4-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m851.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading databricks_sdk-0.36.0-py3-none-any.whl (569 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m569.1/569.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m721.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m691.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, mock, Mako, gunicorn, graphql-core, deprecated, cachetools, opentelemetry-api, graphql-relay, google-auth, gitdb, botocore, alembic, opentelemetry-semantic-conventions, graphene, gitpython, databricks-sdk, opentelemetry-sdk, boto3, sagemaker-core, mlflow-skinny, mlflow, sagemaker-mlflow, sagemaker\n",
      "  Attempting uninstall: mock\n",
      "    Found existing installation: mock 5.1.0\n",
      "    Uninstalling mock-5.1.0:\n",
      "      Successfully uninstalled mock-5.1.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.84\n",
      "    Uninstalling botocore-1.34.84:\n",
      "      Successfully uninstalled botocore-1.34.84\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.84\n",
      "    Uninstalling boto3-1.34.84:\n",
      "      Successfully uninstalled boto3-1.34.84\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.215.0\n",
      "    Uninstalling sagemaker-2.215.0:\n",
      "      Successfully uninstalled sagemaker-2.215.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.32.84 requires botocore==1.34.84, but you have botocore 1.35.49 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.6 alembic-1.13.3 boto3-1.35.49 botocore-1.35.49 cachetools-5.5.0 databricks-sdk-0.36.0 deprecated-1.2.14 gitdb-4.0.11 gitpython-3.1.43 google-auth-2.35.0 graphene-3.4 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.17.1 mlflow-skinny-2.17.1 mock-4.0.3 opentelemetry-api-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 sagemaker-2.232.2 sagemaker-core-1.0.10 sagemaker-mlflow-0.1.0 smmap-5.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "isConfigCell": true,
    "nbpresent": {
     "id": "6427e831-8f89-45c0-b150-0b134397d79a"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"DEMO-breast-cancer-prediction-xgboost-highlevel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "142777ae-c072-448e-b941-72bc75735d01"
    }
   },
   "source": [
    "---\n",
    "## Data sources\n",
    "\n",
    "> Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "> Breast Cancer Wisconsin (Diagnostic) Data Set [https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)].\n",
    "\n",
    "> _Also see:_ Breast Cancer Wisconsin (Diagnostic) Data Set [https://www.kaggle.com/uciml/breast-cancer-wisconsin-data].\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "\n",
    "Let's download the data and save it in the local folder with the name data.csv and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "f8976dad-6897-4c7e-8c95-ae2f53070ef5"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>906024</td>\n",
       "      <td>B</td>\n",
       "      <td>12.700</td>\n",
       "      <td>12.17</td>\n",
       "      <td>80.88</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.08785</td>\n",
       "      <td>0.05794</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.02402</td>\n",
       "      <td>...</td>\n",
       "      <td>13.65</td>\n",
       "      <td>16.92</td>\n",
       "      <td>88.12</td>\n",
       "      <td>566.9</td>\n",
       "      <td>0.1314</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>0.09385</td>\n",
       "      <td>0.08224</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>0.09464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>879523</td>\n",
       "      <td>M</td>\n",
       "      <td>15.120</td>\n",
       "      <td>16.68</td>\n",
       "      <td>98.78</td>\n",
       "      <td>716.6</td>\n",
       "      <td>0.08876</td>\n",
       "      <td>0.09588</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.04079</td>\n",
       "      <td>...</td>\n",
       "      <td>17.77</td>\n",
       "      <td>20.24</td>\n",
       "      <td>117.70</td>\n",
       "      <td>989.5</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.33270</td>\n",
       "      <td>0.12520</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.09740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>90291</td>\n",
       "      <td>M</td>\n",
       "      <td>14.600</td>\n",
       "      <td>23.29</td>\n",
       "      <td>93.97</td>\n",
       "      <td>664.7</td>\n",
       "      <td>0.08682</td>\n",
       "      <td>0.06636</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.05271</td>\n",
       "      <td>...</td>\n",
       "      <td>15.79</td>\n",
       "      <td>31.71</td>\n",
       "      <td>102.20</td>\n",
       "      <td>758.2</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.26750</td>\n",
       "      <td>0.13590</td>\n",
       "      <td>0.2477</td>\n",
       "      <td>0.06836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>9013838</td>\n",
       "      <td>M</td>\n",
       "      <td>11.080</td>\n",
       "      <td>18.83</td>\n",
       "      <td>73.30</td>\n",
       "      <td>361.6</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.21540</td>\n",
       "      <td>0.168900</td>\n",
       "      <td>0.06367</td>\n",
       "      <td>...</td>\n",
       "      <td>13.24</td>\n",
       "      <td>32.82</td>\n",
       "      <td>91.76</td>\n",
       "      <td>508.1</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.9379</td>\n",
       "      <td>0.84020</td>\n",
       "      <td>0.25240</td>\n",
       "      <td>0.4154</td>\n",
       "      <td>0.14030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>859983</td>\n",
       "      <td>M</td>\n",
       "      <td>13.800</td>\n",
       "      <td>15.79</td>\n",
       "      <td>90.43</td>\n",
       "      <td>584.1</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.12800</td>\n",
       "      <td>0.077890</td>\n",
       "      <td>0.05069</td>\n",
       "      <td>...</td>\n",
       "      <td>16.57</td>\n",
       "      <td>20.86</td>\n",
       "      <td>110.30</td>\n",
       "      <td>812.4</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.27790</td>\n",
       "      <td>0.13830</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>0.10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>857156</td>\n",
       "      <td>B</td>\n",
       "      <td>13.490</td>\n",
       "      <td>22.30</td>\n",
       "      <td>86.91</td>\n",
       "      <td>561.0</td>\n",
       "      <td>0.08752</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.047510</td>\n",
       "      <td>0.03384</td>\n",
       "      <td>...</td>\n",
       "      <td>15.15</td>\n",
       "      <td>31.82</td>\n",
       "      <td>99.00</td>\n",
       "      <td>698.8</td>\n",
       "      <td>0.1162</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.22820</td>\n",
       "      <td>0.12820</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.06917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>861598</td>\n",
       "      <td>B</td>\n",
       "      <td>14.640</td>\n",
       "      <td>15.24</td>\n",
       "      <td>95.77</td>\n",
       "      <td>651.9</td>\n",
       "      <td>0.11320</td>\n",
       "      <td>0.13390</td>\n",
       "      <td>0.099660</td>\n",
       "      <td>0.07064</td>\n",
       "      <td>...</td>\n",
       "      <td>16.34</td>\n",
       "      <td>18.24</td>\n",
       "      <td>109.40</td>\n",
       "      <td>803.6</td>\n",
       "      <td>0.1277</td>\n",
       "      <td>0.3089</td>\n",
       "      <td>0.26040</td>\n",
       "      <td>0.13970</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.08473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>907145</td>\n",
       "      <td>B</td>\n",
       "      <td>9.742</td>\n",
       "      <td>19.12</td>\n",
       "      <td>61.93</td>\n",
       "      <td>289.7</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.08333</td>\n",
       "      <td>0.008934</td>\n",
       "      <td>0.01967</td>\n",
       "      <td>...</td>\n",
       "      <td>11.21</td>\n",
       "      <td>23.17</td>\n",
       "      <td>71.79</td>\n",
       "      <td>380.9</td>\n",
       "      <td>0.1398</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>0.02085</td>\n",
       "      <td>0.04589</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.08009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "418   906024         B       12.700         12.17           80.88      495.0   \n",
       "205   879523         M       15.120         16.68           98.78      716.6   \n",
       "385    90291         M       14.600         23.29           93.97      664.7   \n",
       "379  9013838         M       11.080         18.83           73.30      361.6   \n",
       "73    859983         M       13.800         15.79           90.43      584.1   \n",
       "49    857156         B       13.490         22.30           86.91      561.0   \n",
       "89    861598         B       14.640         15.24           95.77      651.9   \n",
       "424   907145         B        9.742         19.12           61.93      289.7   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "418          0.08785           0.05794        0.023600              0.02402   \n",
       "205          0.08876           0.09588        0.075500              0.04079   \n",
       "385          0.08682           0.06636        0.083900              0.05271   \n",
       "379          0.12160           0.21540        0.168900              0.06367   \n",
       "73           0.10070           0.12800        0.077890              0.05069   \n",
       "49           0.08752           0.07698        0.047510              0.03384   \n",
       "89           0.11320           0.13390        0.099660              0.07064   \n",
       "424          0.10750           0.08333        0.008934              0.01967   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "418  ...         13.65          16.92            88.12       566.9   \n",
       "205  ...         17.77          20.24           117.70       989.5   \n",
       "385  ...         15.79          31.71           102.20       758.2   \n",
       "379  ...         13.24          32.82            91.76       508.1   \n",
       "73   ...         16.57          20.86           110.30       812.4   \n",
       "49   ...         15.15          31.82            99.00       698.8   \n",
       "89   ...         16.34          18.24           109.40       803.6   \n",
       "424  ...         11.21          23.17            71.79       380.9   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "418            0.1314             0.1607          0.09385   \n",
       "205            0.1491             0.3331          0.33270   \n",
       "385            0.1312             0.1581          0.26750   \n",
       "379            0.2184             0.9379          0.84020   \n",
       "73             0.1411             0.3542          0.27790   \n",
       "49             0.1162             0.1711          0.22820   \n",
       "89             0.1277             0.3089          0.26040   \n",
       "424            0.1398             0.1352          0.02085   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "418               0.08224          0.2775                  0.09464  \n",
       "205               0.12520          0.3415                  0.09740  \n",
       "385               0.13590          0.2477                  0.06836  \n",
       "379               0.25240          0.4154                  0.14030  \n",
       "73                0.13830          0.2589                  0.10300  \n",
       "49                0.12820          0.2871                  0.06917  \n",
       "89                0.13970          0.3151                  0.08473  \n",
       "424               0.04589          0.3196                  0.08009  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "filename = \"wdbc.csv\"\n",
    "s3.download_file(\n",
    "    f\"sagemaker-example-files-prod-{region}\", \"datasets/tabular/breast_cancer/wdbc.csv\", filename\n",
    ")\n",
    "data = pd.read_csv(filename, header=None)\n",
    "\n",
    "# specify columns extracted from wbdc.names\n",
    "data.columns = [\n",
    "    \"id\",\n",
    "    \"diagnosis\",\n",
    "    \"radius_mean\",\n",
    "    \"texture_mean\",\n",
    "    \"perimeter_mean\",\n",
    "    \"area_mean\",\n",
    "    \"smoothness_mean\",\n",
    "    \"compactness_mean\",\n",
    "    \"concavity_mean\",\n",
    "    \"concave points_mean\",\n",
    "    \"symmetry_mean\",\n",
    "    \"fractal_dimension_mean\",\n",
    "    \"radius_se\",\n",
    "    \"texture_se\",\n",
    "    \"perimeter_se\",\n",
    "    \"area_se\",\n",
    "    \"smoothness_se\",\n",
    "    \"compactness_se\",\n",
    "    \"concavity_se\",\n",
    "    \"concave points_se\",\n",
    "    \"symmetry_se\",\n",
    "    \"fractal_dimension_se\",\n",
    "    \"radius_worst\",\n",
    "    \"texture_worst\",\n",
    "    \"perimeter_worst\",\n",
    "    \"area_worst\",\n",
    "    \"smoothness_worst\",\n",
    "    \"compactness_worst\",\n",
    "    \"concavity_worst\",\n",
    "    \"concave points_worst\",\n",
    "    \"symmetry_worst\",\n",
    "    \"fractal_dimension_worst\",\n",
    "]\n",
    "\n",
    "# save the data\n",
    "data.to_csv(\"data.csv\", sep=\",\", index=False)\n",
    "\n",
    "data.sample(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key observations:\n",
    "* The data has 569 observations and 32 columns.\n",
    "* The first field is the 'id' attribute that we will want to drop before batch inference and add to the final inference output next to the probability of malignancy.\n",
    "* Second field, 'diagnosis', is an indicator of the actual diagnosis ('M' = Malignant; 'B' = Benign).\n",
    "* There are 30 other numeric features that we will use for training and inferencing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace the M/B diagnosis with a 1/0 boolean value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>89864002</td>\n",
       "      <td>0</td>\n",
       "      <td>11.710</td>\n",
       "      <td>15.45</td>\n",
       "      <td>75.03</td>\n",
       "      <td>420.3</td>\n",
       "      <td>0.11500</td>\n",
       "      <td>0.07281</td>\n",
       "      <td>0.040060</td>\n",
       "      <td>0.03250</td>\n",
       "      <td>...</td>\n",
       "      <td>13.060</td>\n",
       "      <td>18.16</td>\n",
       "      <td>84.16</td>\n",
       "      <td>516.4</td>\n",
       "      <td>0.14600</td>\n",
       "      <td>0.11150</td>\n",
       "      <td>0.10870</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.07806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>905189</td>\n",
       "      <td>0</td>\n",
       "      <td>16.140</td>\n",
       "      <td>14.86</td>\n",
       "      <td>104.30</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.09495</td>\n",
       "      <td>0.08501</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.04528</td>\n",
       "      <td>...</td>\n",
       "      <td>17.710</td>\n",
       "      <td>19.58</td>\n",
       "      <td>115.90</td>\n",
       "      <td>947.9</td>\n",
       "      <td>0.12060</td>\n",
       "      <td>0.17220</td>\n",
       "      <td>0.23100</td>\n",
       "      <td>0.11290</td>\n",
       "      <td>0.2778</td>\n",
       "      <td>0.07012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>8910996</td>\n",
       "      <td>0</td>\n",
       "      <td>9.742</td>\n",
       "      <td>15.67</td>\n",
       "      <td>61.50</td>\n",
       "      <td>289.9</td>\n",
       "      <td>0.09037</td>\n",
       "      <td>0.04689</td>\n",
       "      <td>0.011030</td>\n",
       "      <td>0.01407</td>\n",
       "      <td>...</td>\n",
       "      <td>10.750</td>\n",
       "      <td>20.88</td>\n",
       "      <td>68.09</td>\n",
       "      <td>355.2</td>\n",
       "      <td>0.14670</td>\n",
       "      <td>0.09370</td>\n",
       "      <td>0.04043</td>\n",
       "      <td>0.05159</td>\n",
       "      <td>0.2841</td>\n",
       "      <td>0.08175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>914101</td>\n",
       "      <td>0</td>\n",
       "      <td>12.460</td>\n",
       "      <td>12.83</td>\n",
       "      <td>78.83</td>\n",
       "      <td>477.3</td>\n",
       "      <td>0.07372</td>\n",
       "      <td>0.04043</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.01149</td>\n",
       "      <td>...</td>\n",
       "      <td>13.190</td>\n",
       "      <td>16.36</td>\n",
       "      <td>83.24</td>\n",
       "      <td>534.0</td>\n",
       "      <td>0.09439</td>\n",
       "      <td>0.06477</td>\n",
       "      <td>0.01674</td>\n",
       "      <td>0.02680</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.07028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>911384</td>\n",
       "      <td>0</td>\n",
       "      <td>14.920</td>\n",
       "      <td>14.93</td>\n",
       "      <td>96.45</td>\n",
       "      <td>686.9</td>\n",
       "      <td>0.08098</td>\n",
       "      <td>0.08549</td>\n",
       "      <td>0.055390</td>\n",
       "      <td>0.03221</td>\n",
       "      <td>...</td>\n",
       "      <td>17.180</td>\n",
       "      <td>18.22</td>\n",
       "      <td>112.00</td>\n",
       "      <td>906.6</td>\n",
       "      <td>0.10650</td>\n",
       "      <td>0.27910</td>\n",
       "      <td>0.31510</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>0.08273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>1</td>\n",
       "      <td>12.450</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.470</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.52490</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>85922302</td>\n",
       "      <td>1</td>\n",
       "      <td>12.680</td>\n",
       "      <td>23.84</td>\n",
       "      <td>82.69</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.11220</td>\n",
       "      <td>0.12620</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>0.06873</td>\n",
       "      <td>...</td>\n",
       "      <td>17.090</td>\n",
       "      <td>33.47</td>\n",
       "      <td>111.80</td>\n",
       "      <td>888.3</td>\n",
       "      <td>0.18510</td>\n",
       "      <td>0.40610</td>\n",
       "      <td>0.40240</td>\n",
       "      <td>0.17160</td>\n",
       "      <td>0.3383</td>\n",
       "      <td>0.10310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>7.760</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "344  89864002          0       11.710         15.45           75.03   \n",
       "406    905189          0       16.140         14.86          104.30   \n",
       "273   8910996          0        9.742         15.67           61.50   \n",
       "493    914101          0       12.460         12.83           78.83   \n",
       "472    911384          0       14.920         14.93           96.45   \n",
       "5      843786          1       12.450         15.70           82.57   \n",
       "64   85922302          1       12.680         23.84           82.69   \n",
       "568     92751          0        7.760         24.54           47.92   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "344      420.3          0.11500           0.07281        0.040060   \n",
       "406      800.0          0.09495           0.08501        0.055000   \n",
       "273      289.9          0.09037           0.04689        0.011030   \n",
       "493      477.3          0.07372           0.04043        0.007173   \n",
       "472      686.9          0.08098           0.08549        0.055390   \n",
       "5        477.1          0.12780           0.17000        0.157800   \n",
       "64       499.0          0.11220           0.12620        0.112800   \n",
       "568      181.0          0.05263           0.04362        0.000000   \n",
       "\n",
       "     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "344              0.03250  ...        13.060          18.16            84.16   \n",
       "406              0.04528  ...        17.710          19.58           115.90   \n",
       "273              0.01407  ...        10.750          20.88            68.09   \n",
       "493              0.01149  ...        13.190          16.36            83.24   \n",
       "472              0.03221  ...        17.180          18.22           112.00   \n",
       "5                0.08089  ...        15.470          23.75           103.40   \n",
       "64               0.06873  ...        17.090          33.47           111.80   \n",
       "568              0.00000  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "344       516.4           0.14600            0.11150          0.10870   \n",
       "406       947.9           0.12060            0.17220          0.23100   \n",
       "273       355.2           0.14670            0.09370          0.04043   \n",
       "493       534.0           0.09439            0.06477          0.01674   \n",
       "472       906.6           0.10650            0.27910          0.31510   \n",
       "5         741.6           0.17910            0.52490          0.53550   \n",
       "64        888.3           0.18510            0.40610          0.40240   \n",
       "568       268.6           0.08996            0.06444          0.00000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "344               0.07864          0.2765                  0.07806  \n",
       "406               0.11290          0.2778                  0.07012  \n",
       "273               0.05159          0.2841                  0.08175  \n",
       "493               0.02680          0.2280                  0.07028  \n",
       "472               0.11470          0.2688                  0.08273  \n",
       "5                 0.17410          0.3985                  0.12440  \n",
       "64                0.17160          0.3383                  0.10310  \n",
       "568               0.00000          0.2871                  0.07039  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"diagnosis\"] = data[\"diagnosis\"].apply(lambda x: ((x == \"M\")) + 0)\n",
    "data.sample(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data as follows: 80% for training, 10% for validation and let's set 10% aside for our batch inference job. In addition, let's drop the 'id' field on the training set and validation set as 'id' is not a training feature. For our batch set however, we keep the 'id' feature. We'll want to filter it out prior to running our inferences so that the input data features match the ones of training set and then ultimately, we'll want to join it with inference result. We are however dropping the diagnosis attribute for the batch set since this is what we'll try to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data split in three sets, training, validation and batch inference\n",
    "rand_split = np.random.rand(len(data))\n",
    "train_list = rand_split < 0.8\n",
    "val_list = (rand_split >= 0.8) & (rand_split < 0.9)\n",
    "batch_list = rand_split >= 0.9\n",
    "\n",
    "data_train = data[train_list].drop([\"id\"], axis=1)\n",
    "data_val = data[val_list].drop([\"id\"], axis=1)\n",
    "data_batch = data[batch_list].drop([\"diagnosis\"], axis=1)\n",
    "data_batch_noID = data_batch.drop([\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ff9d10f9-b611-423b-80da-6dcdafd1c8b9"
    }
   },
   "source": [
    "Let's upload those data sets in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "cd8e3431-79d9-40b6-91d1-d67cd61894e7"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-002969758287/DEMO-breast-cancer-prediction-xgboost-highlevel/batch/batch_data_noID.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = \"train_data.csv\"\n",
    "data_train.to_csv(train_file, index=False, header=False)\n",
    "sess.upload_data(train_file, key_prefix=\"{}/train\".format(prefix))\n",
    "\n",
    "validation_file = \"validation_data.csv\"\n",
    "data_val.to_csv(validation_file, index=False, header=False)\n",
    "sess.upload_data(validation_file, key_prefix=\"{}/validation\".format(prefix))\n",
    "\n",
    "batch_file = \"batch_data.csv\"\n",
    "data_batch.to_csv(batch_file, index=False, header=False)\n",
    "sess.upload_data(batch_file, key_prefix=\"{}/batch\".format(prefix))\n",
    "\n",
    "batch_file_noID = \"batch_data_noID.csv\"\n",
    "data_batch_noID.to_csv(batch_file_noID, index=False, header=False)\n",
    "sess.upload_data(batch_file_noID, key_prefix=\"{}/batch\".format(prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "71cbcebd-a2a5-419e-8e50-b2bc0909f564"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Training job and model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bd113b8e-adc1-4091-a26f-a426149fe604"
    }
   },
   "source": [
    "The below cell uses the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to kick off the training job using both our training set and validation set. Not that the objective is set to 'binary:logistic' which trains a model to output a probability between 0 and 1 (here the probability of a tumor being malignant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "f3b125ad-a2d5-464c-8cfa-bd203034eee4"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: xgb-2024-10-25-22-29-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-25 22:29:15 Starting - Starting the training job...\n",
      "2024-10-25 22:29:32 Starting - Preparing the instances for training...\n",
      "2024-10-25 22:30:19 Downloading - Downloading the training image......\n",
      "2024-10-25 22:31:10 Training - Training image download completed. Training in progress..\u001b[34m[2024-10-25 22:31:21.048 ip-10-0-139-186.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:31:21.073 ip-10-0-139-186.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Determined 0 GPU(s) available on the instance.\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] File path /opt/ml/input/data/train of input files\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Making smlinks from folder /opt/ml/input/data/train to folder /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] creating symlink between Path /opt/ml/input/data/train/train_data.csv and destination /tmp/sagemaker_xgboost_input_data/train_data.csv-7224955886429030101\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] files path: /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] File path /opt/ml/input/data/validation of input files\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Making smlinks from folder /opt/ml/input/data/validation to folder /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] creating symlink between Path /opt/ml/input/data/validation/validation_data.csv and destination /tmp/sagemaker_xgboost_input_data/validation_data.csv-5185771738728791933\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] files path: /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Train matrix has 439 rows and 30 columns\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Validation matrix has 61 rows\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:31:21.557 ip-10-0-139-186.ec2.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:31:21.557 ip-10-0-139-186.ec2.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:31:21.558 ip-10-0-139-186.ec2.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:31:21.558 ip-10-0-139-186.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:31:21:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[0]#011train-logloss:0.54776#011validation-logloss:0.55469\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:31:21.581 ip-10-0-139-186.ec2.internal:7 INFO hook.py:427] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:31:21.584 ip-10-0-139-186.ec2.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-logloss:0.44874#011validation-logloss:0.46359\u001b[0m\n",
      "\u001b[34m[2]#011train-logloss:0.37290#011validation-logloss:0.39464\u001b[0m\n",
      "\u001b[34m[3]#011train-logloss:0.31696#011validation-logloss:0.34211\u001b[0m\n",
      "\u001b[34m[4]#011train-logloss:0.27380#011validation-logloss:0.30846\u001b[0m\n",
      "\u001b[34m[5]#011train-logloss:0.24060#011validation-logloss:0.27552\u001b[0m\n",
      "\u001b[34m[6]#011train-logloss:0.21264#011validation-logloss:0.24646\u001b[0m\n",
      "\u001b[34m[7]#011train-logloss:0.18935#011validation-logloss:0.21981\u001b[0m\n",
      "\u001b[34m[8]#011train-logloss:0.17000#011validation-logloss:0.20540\u001b[0m\n",
      "\u001b[34m[9]#011train-logloss:0.15334#011validation-logloss:0.19379\u001b[0m\n",
      "\u001b[34m[10]#011train-logloss:0.13827#011validation-logloss:0.18332\u001b[0m\n",
      "\u001b[34m[11]#011train-logloss:0.12746#011validation-logloss:0.17160\u001b[0m\n",
      "\u001b[34m[12]#011train-logloss:0.12089#011validation-logloss:0.17028\u001b[0m\n",
      "\u001b[34m[13]#011train-logloss:0.11170#011validation-logloss:0.16343\u001b[0m\n",
      "\u001b[34m[14]#011train-logloss:0.10330#011validation-logloss:0.15650\u001b[0m\n",
      "\u001b[34m[15]#011train-logloss:0.09591#011validation-logloss:0.15178\u001b[0m\n",
      "\u001b[34m[16]#011train-logloss:0.09202#011validation-logloss:0.15263\u001b[0m\n",
      "\u001b[34m[17]#011train-logloss:0.08536#011validation-logloss:0.14829\u001b[0m\n",
      "\u001b[34m[18]#011train-logloss:0.08264#011validation-logloss:0.14135\u001b[0m\n",
      "\u001b[34m[19]#011train-logloss:0.07959#011validation-logloss:0.13916\u001b[0m\n",
      "\u001b[34m[20]#011train-logloss:0.07709#011validation-logloss:0.13852\u001b[0m\n",
      "\u001b[34m[21]#011train-logloss:0.07461#011validation-logloss:0.13746\u001b[0m\n",
      "\u001b[34m[22]#011train-logloss:0.07459#011validation-logloss:0.13814\u001b[0m\n",
      "\u001b[34m[23]#011train-logloss:0.07255#011validation-logloss:0.13713\u001b[0m\n",
      "\u001b[34m[24]#011train-logloss:0.07060#011validation-logloss:0.13705\u001b[0m\n",
      "\u001b[34m[25]#011train-logloss:0.07060#011validation-logloss:0.13696\u001b[0m\n",
      "\u001b[34m[26]#011train-logloss:0.06922#011validation-logloss:0.13821\u001b[0m\n",
      "\u001b[34m[27]#011train-logloss:0.06921#011validation-logloss:0.13848\u001b[0m\n",
      "\u001b[34m[28]#011train-logloss:0.06732#011validation-logloss:0.13780\u001b[0m\n",
      "\u001b[34m[29]#011train-logloss:0.06731#011validation-logloss:0.13800\u001b[0m\n",
      "\u001b[34m[30]#011train-logloss:0.06732#011validation-logloss:0.13839\u001b[0m\n",
      "\u001b[34m[31]#011train-logloss:0.06731#011validation-logloss:0.13798\u001b[0m\n",
      "\u001b[34m[32]#011train-logloss:0.06731#011validation-logloss:0.13802\u001b[0m\n",
      "\u001b[34m[33]#011train-logloss:0.06731#011validation-logloss:0.13814\u001b[0m\n",
      "\u001b[34m[34]#011train-logloss:0.06732#011validation-logloss:0.13829\u001b[0m\n",
      "\u001b[34m[35]#011train-logloss:0.06734#011validation-logloss:0.13866\u001b[0m\n",
      "\u001b[34m[36]#011train-logloss:0.06733#011validation-logloss:0.13849\u001b[0m\n",
      "\u001b[34m[37]#011train-logloss:0.06731#011validation-logloss:0.13818\u001b[0m\n",
      "\u001b[34m[38]#011train-logloss:0.06732#011validation-logloss:0.13837\u001b[0m\n",
      "\u001b[34m[39]#011train-logloss:0.06731#011validation-logloss:0.13800\u001b[0m\n",
      "\u001b[34m[40]#011train-logloss:0.06590#011validation-logloss:0.13581\u001b[0m\n",
      "\u001b[34m[41]#011train-logloss:0.06591#011validation-logloss:0.13568\u001b[0m\n",
      "\u001b[34m[42]#011train-logloss:0.06591#011validation-logloss:0.13575\u001b[0m\n",
      "\u001b[34m[43]#011train-logloss:0.06590#011validation-logloss:0.13591\u001b[0m\n",
      "\u001b[34m[44]#011train-logloss:0.06590#011validation-logloss:0.13599\u001b[0m\n",
      "\u001b[34m[45]#011train-logloss:0.06590#011validation-logloss:0.13600\u001b[0m\n",
      "\u001b[34m[46]#011train-logloss:0.06590#011validation-logloss:0.13592\u001b[0m\n",
      "\u001b[34m[47]#011train-logloss:0.06590#011validation-logloss:0.13597\u001b[0m\n",
      "\u001b[34m[48]#011train-logloss:0.06590#011validation-logloss:0.13614\u001b[0m\n",
      "\u001b[34m[49]#011train-logloss:0.06590#011validation-logloss:0.13602\u001b[0m\n",
      "\u001b[34m[50]#011train-logloss:0.06590#011validation-logloss:0.13605\u001b[0m\n",
      "\u001b[34m[51]#011train-logloss:0.06590#011validation-logloss:0.13615\u001b[0m\n",
      "\u001b[34m[52]#011train-logloss:0.06590#011validation-logloss:0.13606\u001b[0m\n",
      "\u001b[34m[53]#011train-logloss:0.06590#011validation-logloss:0.13623\u001b[0m\n",
      "\u001b[34m[54]#011train-logloss:0.06590#011validation-logloss:0.13620\u001b[0m\n",
      "\u001b[34m[55]#011train-logloss:0.06590#011validation-logloss:0.13617\u001b[0m\n",
      "\u001b[34m[56]#011train-logloss:0.06590#011validation-logloss:0.13612\u001b[0m\n",
      "\u001b[34m[57]#011train-logloss:0.06590#011validation-logloss:0.13585\u001b[0m\n",
      "\u001b[34m[58]#011train-logloss:0.06590#011validation-logloss:0.13580\u001b[0m\n",
      "\u001b[34m[59]#011train-logloss:0.06590#011validation-logloss:0.13604\u001b[0m\n",
      "\u001b[34m[60]#011train-logloss:0.06590#011validation-logloss:0.13624\u001b[0m\n",
      "\u001b[34m[61]#011train-logloss:0.06590#011validation-logloss:0.13629\u001b[0m\n",
      "\u001b[34m[62]#011train-logloss:0.06434#011validation-logloss:0.13420\u001b[0m\n",
      "\u001b[34m[63]#011train-logloss:0.06434#011validation-logloss:0.13428\u001b[0m\n",
      "\u001b[34m[64]#011train-logloss:0.06434#011validation-logloss:0.13396\u001b[0m\n",
      "\u001b[34m[65]#011train-logloss:0.06434#011validation-logloss:0.13420\u001b[0m\n",
      "\u001b[34m[66]#011train-logloss:0.06434#011validation-logloss:0.13427\u001b[0m\n",
      "\u001b[34m[67]#011train-logloss:0.06436#011validation-logloss:0.13453\u001b[0m\n",
      "\u001b[34m[68]#011train-logloss:0.06434#011validation-logloss:0.13419\u001b[0m\n",
      "\u001b[34m[69]#011train-logloss:0.06434#011validation-logloss:0.13403\u001b[0m\n",
      "\u001b[34m[70]#011train-logloss:0.06436#011validation-logloss:0.13447\u001b[0m\n",
      "\u001b[34m[71]#011train-logloss:0.06434#011validation-logloss:0.13428\u001b[0m\n",
      "\u001b[34m[72]#011train-logloss:0.06435#011validation-logloss:0.13432\u001b[0m\n",
      "\u001b[34m[73]#011train-logloss:0.06435#011validation-logloss:0.13434\u001b[0m\n",
      "\u001b[34m[74]#011train-logloss:0.06435#011validation-logloss:0.13446\u001b[0m\n",
      "\u001b[34m[75]#011train-logloss:0.06436#011validation-logloss:0.13452\u001b[0m\n",
      "\u001b[34m[76]#011train-logloss:0.06434#011validation-logloss:0.13419\u001b[0m\n",
      "\u001b[34m[77]#011train-logloss:0.06434#011validation-logloss:0.13426\u001b[0m\n",
      "\u001b[34m[78]#011train-logloss:0.06435#011validation-logloss:0.13430\u001b[0m\n",
      "\u001b[34m[79]#011train-logloss:0.06434#011validation-logloss:0.13420\u001b[0m\n",
      "\u001b[34m[80]#011train-logloss:0.06435#011validation-logloss:0.13436\u001b[0m\n",
      "\u001b[34m[81]#011train-logloss:0.06436#011validation-logloss:0.13451\u001b[0m\n",
      "\u001b[34m[82]#011train-logloss:0.06435#011validation-logloss:0.13444\u001b[0m\n",
      "\u001b[34m[83]#011train-logloss:0.06434#011validation-logloss:0.13427\u001b[0m\n",
      "\u001b[34m[84]#011train-logloss:0.06435#011validation-logloss:0.13437\u001b[0m\n",
      "\u001b[34m[85]#011train-logloss:0.06435#011validation-logloss:0.13439\u001b[0m\n",
      "\u001b[34m[86]#011train-logloss:0.06436#011validation-logloss:0.13453\u001b[0m\n",
      "\u001b[34m[87]#011train-logloss:0.06434#011validation-logloss:0.13426\u001b[0m\n",
      "\u001b[34m[88]#011train-logloss:0.06435#011validation-logloss:0.13436\u001b[0m\n",
      "\u001b[34m[89]#011train-logloss:0.06434#011validation-logloss:0.13417\u001b[0m\n",
      "\u001b[34m[90]#011train-logloss:0.06434#011validation-logloss:0.13403\u001b[0m\n",
      "\u001b[34m[91]#011train-logloss:0.06435#011validation-logloss:0.13435\u001b[0m\n",
      "\u001b[34m[92]#011train-logloss:0.06434#011validation-logloss:0.13392\u001b[0m\n",
      "\u001b[34m[93]#011train-logloss:0.06436#011validation-logloss:0.13360\u001b[0m\n",
      "\u001b[34m[94]#011train-logloss:0.06437#011validation-logloss:0.13353\u001b[0m\n",
      "\u001b[34m[95]#011train-logloss:0.06447#011validation-logloss:0.13308\u001b[0m\n",
      "\u001b[34m[96]#011train-logloss:0.06442#011validation-logloss:0.13326\u001b[0m\n",
      "\u001b[34m[97]#011train-logloss:0.06438#011validation-logloss:0.13349\u001b[0m\n",
      "\u001b[34m[98]#011train-logloss:0.06439#011validation-logloss:0.13340\u001b[0m\n",
      "\u001b[34m[99]#011train-logloss:0.06435#011validation-logloss:0.13370\u001b[0m\n",
      "\n",
      "2024-10-25 22:31:38 Uploading - Uploading generated training model\n",
      "2024-10-25 22:31:38 Completed - Training job completed\n",
      "Training seconds: 100\n",
      "Billable seconds: 100\n",
      "CPU times: user 633 ms, sys: 32.4 ms, total: 666 ms\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "job_name = \"xgb-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "output_location = \"s3://{}/{}/output/{}\".format(bucket, prefix, job_name)\n",
    "image = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\", region=boto3.Session().region_name, version=\"1.7-1\"\n",
    ")\n",
    "\n",
    "sm_estimator = sagemaker.estimator.Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size=50,\n",
    "    input_mode=\"File\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "sm_estimator.set_hyperparameters(\n",
    "    objective=\"binary:logistic\",\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    verbosity=0,\n",
    "    num_round=100,\n",
    ")\n",
    "\n",
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train\".format(bucket, prefix),\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validation\".format(bucket, prefix),\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}\n",
    "\n",
    "# Start training by calling the fit method in the estimator\n",
    "sm_estimator.fit(inputs=data_channels, job_name=job_name, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "397fb60a-c48b-453f-88ea-4d832b70c919"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Batch Transform\n",
    "\n",
    "In SageMaker Batch Transform, we introduced 3 new attributes - __input_filter__, __join_source__ and __output_filter__. In the below cell, we use the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to kick-off several Batch Transform jobs using different configurations of these 3 new attributes. Please refer to [this page](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html) to learn more about how to use them.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a transform job with the default configurations\n",
    "Let's first skip these 3 new attributes and inspect the inference results. We'll use it as a baseline to compare to the results with data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-10-25-22-34-14-595\n",
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2024-10-25-22-34-15-374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................\n",
      "\u001b[34m[2024-10-25:22:41:48:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:48:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:48:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.9/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:50:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:50:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:50:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:50:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:50:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:50:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:51:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:51:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:51:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:51:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:51:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:51:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:22:41:54 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:22:41:54 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:22:41:54 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:22:41:54 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-10-25T22:41:54.653:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:54:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:54:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:22:41:54 +0000] \"POST /invocations HTTP/1.1\" 200 1380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:22:41:54 +0000] \"POST /invocations HTTP/1.1\" 200 1380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:48:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:48:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:48:INFO] nginx config: \u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:48:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:48:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:48:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.9/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:41:48 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:41:48 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:41:48 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:41:48 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.9/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:41:48 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:41:48 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:41:48 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:41:48 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:50:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:50:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:50:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:50:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:50:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:50:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:51:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:51:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:51:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:51:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:50:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:50:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:50:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:50:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:50:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:50:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:51:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:51:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:51:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:51:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:51:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:51:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:51:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:51:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:22:41:54 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:22:41:54 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:22:41:54 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:22:41:54 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-10-25T22:41:54.653:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:41:54:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:41:54:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:22:41:54 +0000] \"POST /invocations HTTP/1.1\" 200 1380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:22:41:54 +0000] \"POST /invocations HTTP/1.1\" 200 1380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "CPU times: user 996 ms, sys: 75.4 ms, total: 1.07 s\n",
      "Wall time: 8min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sm_transformer = sm_estimator.transformer(1, \"ml.m4.xlarge\")\n",
    "\n",
    "# start a transform job\n",
    "input_location = \"s3://{}/{}/batch/{}\".format(\n",
    "    bucket, prefix, batch_file_noID\n",
    ")  # use input data without ID column\n",
    "sm_transformer.transform(input_location, content_type=\"text/csv\", split_type=\"Line\")\n",
    "sm_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the output of the Batch Transform job in S3. It should show the list probabilities of tumors being malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_csv_output_from_s3(s3uri, batch_file):\n",
    "    file_name = \"{}.out\".format(batch_file)\n",
    "    match = re.match(\"s3://([^/]+)/(.*)\", \"{}/{}\".format(s3uri, file_name))\n",
    "    output_bucket, output_prefix = match.group(1), match.group(2)\n",
    "    s3.download_file(output_bucket, output_prefix, file_name)\n",
    "    return pd.read_csv(file_name, sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.884313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.992090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.079594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.011179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.884313\n",
       "1  0.992090\n",
       "2  0.005741\n",
       "3  0.048952\n",
       "4  0.005741\n",
       "5  0.079594\n",
       "6  0.006975\n",
       "7  0.011179"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = get_csv_output_from_s3(sm_transformer.output_path, batch_file_noID)\n",
    "output_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Join the input and the prediction results \n",
    "Now, let's associate the prediction results with their corresponding input records. We can also use the __input_filter__ to exclude the ID column easily and there's no need to have a separate file in S3.\n",
    "\n",
    "* Set __input_filter__ to \"$[1:]\": indicates that we are excluding column 0 (the 'ID') before processing the inferences and keeping everything from column 1 to the last column (all the features or predictors)  \n",
    "  \n",
    "  \n",
    "* Set __join_source__ to \"Input\": indicates our desire to join the input data with the inference results  \n",
    "\n",
    "* Leave __output_filter__ to default ('$'), indicating that the joined input and inference results be will saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2024-10-25-22-43-26-716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................\u001b[34m[2024-10-25:22:50:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:43:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.9/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:49:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:49:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:22:50:49 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:22:50:49 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:22:50:49 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:22:50:49 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:49:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:49:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:22:50:49 +0000] \"POST /invocations HTTP/1.1\" 200 1380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:49:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:49:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:22:50:49 +0000] \"POST /invocations HTTP/1.1\" 200 1380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-10-25T22:50:49.130:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "\u001b[34m[2024-10-25:22:50:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:43:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:43:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:43:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.9/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:50:43 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:50:43 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:50:43 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.9/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:50:43 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:50:43 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:50:43 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2024-10-25 22:50:43 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2024-10-25 22:50:43 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:49:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:49:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:22:50:49 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:22:50:49 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:22:50:49 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:22:50:49 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:49:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:22:50:49:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:22:50:49 +0000] \"POST /invocations HTTP/1.1\" 200 1380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:49:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:22:50:49:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:22:50:49 +0000] \"POST /invocations HTTP/1.1\" 200 1380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-10-25T22:50:49.130:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# content_type / accept and split_type / assemble_with are required to use IO joining feature\n",
    "sm_transformer.assemble_with = \"Line\"\n",
    "sm_transformer.accept = \"text/csv\"\n",
    "\n",
    "# start a transform job\n",
    "input_location = \"s3://{}/{}/batch/{}\".format(\n",
    "    bucket, prefix, batch_file\n",
    ")  # use input data with ID column cause InputFilter will filter it out\n",
    "sm_transformer.transform(\n",
    "    input_location,\n",
    "    split_type=\"Line\",\n",
    "    content_type=\"text/csv\",\n",
    "    input_filter=\"$[1:]\",\n",
    "    join_source=\"Input\",\n",
    ")\n",
    "sm_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the output of the Batch Transform job in S3. It should show the list of tumors identified by their original feature columns and their corresponding probabilities of being malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>844981</td>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.093530</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.54010</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.884313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84862001</td>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.17220</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>...</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.42330</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "      <td>0.992090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8510824</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>...</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>855167</td>\n",
       "      <td>13.440</td>\n",
       "      <td>21.58</td>\n",
       "      <td>86.18</td>\n",
       "      <td>563.0</td>\n",
       "      <td>0.08162</td>\n",
       "      <td>0.06031</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>...</td>\n",
       "      <td>30.25</td>\n",
       "      <td>102.50</td>\n",
       "      <td>787.9</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.20430</td>\n",
       "      <td>0.20850</td>\n",
       "      <td>0.11120</td>\n",
       "      <td>0.2994</td>\n",
       "      <td>0.07146</td>\n",
       "      <td>0.048952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85713702</td>\n",
       "      <td>8.196</td>\n",
       "      <td>16.84</td>\n",
       "      <td>51.71</td>\n",
       "      <td>201.9</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.01588</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>...</td>\n",
       "      <td>21.96</td>\n",
       "      <td>57.26</td>\n",
       "      <td>242.2</td>\n",
       "      <td>0.1297</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.06880</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.07409</td>\n",
       "      <td>0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>857156</td>\n",
       "      <td>13.490</td>\n",
       "      <td>22.30</td>\n",
       "      <td>86.91</td>\n",
       "      <td>561.0</td>\n",
       "      <td>0.08752</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.04751</td>\n",
       "      <td>0.033840</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>31.82</td>\n",
       "      <td>99.00</td>\n",
       "      <td>698.8</td>\n",
       "      <td>0.1162</td>\n",
       "      <td>0.17110</td>\n",
       "      <td>0.22820</td>\n",
       "      <td>0.12820</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.06917</td>\n",
       "      <td>0.079594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>85759902</td>\n",
       "      <td>11.520</td>\n",
       "      <td>18.75</td>\n",
       "      <td>73.34</td>\n",
       "      <td>409.0</td>\n",
       "      <td>0.09524</td>\n",
       "      <td>0.05473</td>\n",
       "      <td>0.03036</td>\n",
       "      <td>0.022780</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>...</td>\n",
       "      <td>22.47</td>\n",
       "      <td>81.81</td>\n",
       "      <td>506.2</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.08720</td>\n",
       "      <td>0.09076</td>\n",
       "      <td>0.06316</td>\n",
       "      <td>0.3306</td>\n",
       "      <td>0.07036</td>\n",
       "      <td>0.006975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>858970</td>\n",
       "      <td>10.170</td>\n",
       "      <td>14.88</td>\n",
       "      <td>64.55</td>\n",
       "      <td>311.9</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>0.08061</td>\n",
       "      <td>0.01084</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>...</td>\n",
       "      <td>17.45</td>\n",
       "      <td>69.86</td>\n",
       "      <td>368.6</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.09866</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.02579</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>0.08020</td>\n",
       "      <td>0.011179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1      2       3      4        5        6        7   \\\n",
       "0    844981  13.000  21.82   87.50  519.8  0.12730  0.19320  0.18590   \n",
       "1  84862001  16.130  20.68  108.10  798.8  0.11700  0.20220  0.17220   \n",
       "2   8510824   9.504  12.44   60.34  273.9  0.10240  0.06492  0.02956   \n",
       "3    855167  13.440  21.58   86.18  563.0  0.08162  0.06031  0.03110   \n",
       "4  85713702   8.196  16.84   51.71  201.9  0.08600  0.05943  0.01588   \n",
       "5    857156  13.490  22.30   86.91  561.0  0.08752  0.07698  0.04751   \n",
       "6  85759902  11.520  18.75   73.34  409.0  0.09524  0.05473  0.03036   \n",
       "7    858970  10.170  14.88   64.55  311.9  0.11340  0.08061  0.01084   \n",
       "\n",
       "         8       9   ...     22      23      24      25       26       27  \\\n",
       "0  0.093530  0.2350  ...  30.73  106.20   739.3  0.1703  0.54010  0.53900   \n",
       "1  0.102800  0.2164  ...  31.48  136.80  1315.0  0.1789  0.42330  0.47840   \n",
       "2  0.020760  0.1815  ...  15.66   65.13   314.9  0.1324  0.11480  0.08867   \n",
       "3  0.020310  0.1784  ...  30.25  102.50   787.9  0.1094  0.20430  0.20850   \n",
       "4  0.005917  0.1769  ...  21.96   57.26   242.2  0.1297  0.13570  0.06880   \n",
       "5  0.033840  0.1809  ...  31.82   99.00   698.8  0.1162  0.17110  0.22820   \n",
       "6  0.022780  0.1920  ...  22.47   81.81   506.2  0.1249  0.08720  0.09076   \n",
       "7  0.012900  0.2743  ...  17.45   69.86   368.6  0.1275  0.09866  0.02168   \n",
       "\n",
       "        28      29       30        31  \n",
       "0  0.20600  0.4378  0.10720  0.884313  \n",
       "1  0.20730  0.3706  0.11420  0.992090  \n",
       "2  0.06227  0.2450  0.07773  0.005741  \n",
       "3  0.11120  0.2994  0.07146  0.048952  \n",
       "4  0.02564  0.3105  0.07409  0.005741  \n",
       "5  0.12820  0.2871  0.06917  0.079594  \n",
       "6  0.06316  0.3306  0.07036  0.006975  \n",
       "7  0.02579  0.3557  0.08020  0.011179  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = get_csv_output_from_s3(sm_transformer.output_path, batch_file)\n",
    "output_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Update the output filter to keep only ID and prediction results\n",
    "Let's change __output_filter__ to \"$[0,-1]\", indicating that when presenting the output, we only want to keep column 0 (the 'ID') and the last column (the inference result i.e. the probability of a given tumor to be malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2024-10-25-22-57-34-970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................\u001b[34m[2024-10-25:23:04:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:22:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:22:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.9/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.9/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:28:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:23:04:28 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:28:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:23:04:28 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:28:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:23:04:28 +0000] \"POST /invocations HTTP/1.1\" 200 1380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:28:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:23:04:28 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:28:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:23:04:28 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:28:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:23:04:28 +0000] \"POST /invocations HTTP/1.1\" 200 1380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-10-25T23:04:28.042:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "\u001b[34m[2024-10-25:23:04:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:22:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:22:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:22:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.9/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2024-10-25 23:04:22 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [18] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [18] [INFO] Listening at: unix:/tmp/gunicorn.sock (18)\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [18] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.9/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2024-10-25 23:04:22 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:24:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:28:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:23:04:28 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:28:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:23:04:28 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2024-10-25:23:04:28:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [25/Oct/2024:23:04:28 +0000] \"POST /invocations HTTP/1.1\" 200 1380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:28:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:23:04:28 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:28:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:23:04:28 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2024-10-25:23:04:28:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [25/Oct/2024:23:04:28 +0000] \"POST /invocations HTTP/1.1\" 200 1380 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2024-10-25T23:04:28.042:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# start another transform job\n",
    "sm_transformer.transform(\n",
    "    input_location,\n",
    "    split_type=\"Line\",\n",
    "    content_type=\"text/csv\",\n",
    "    input_filter=\"$[1:]\",\n",
    "    join_source=\"Input\",\n",
    "    output_filter=\"$[0,-1]\",\n",
    ")\n",
    "sm_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's inspect the output of the Batch Transform job in S3 again. It should show 2 columns: the ID and their corresponding probabilities of being malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>844981</td>\n",
       "      <td>0.884313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84862001</td>\n",
       "      <td>0.992090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8510824</td>\n",
       "      <td>0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>855167</td>\n",
       "      <td>0.048952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85713702</td>\n",
       "      <td>0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>857156</td>\n",
       "      <td>0.079594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>85759902</td>\n",
       "      <td>0.006975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>858970</td>\n",
       "      <td>0.011179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0    844981  0.884313\n",
       "1  84862001  0.992090\n",
       "2   8510824  0.005741\n",
       "3    855167  0.048952\n",
       "4  85713702  0.005741\n",
       "5    857156  0.079594\n",
       "6  85759902  0.006975\n",
       "7    858970  0.011179"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = get_csv_output_from_s3(sm_transformer.output_path, batch_file)\n",
    "output_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create_model(role=role, image_uri=XGBOOST_IMAGE)In summary, we can use newly introduced 3 attributes - __input_filter__, __join_source__, __output_filter__ to \n",
    "1. Filter / select useful features from the input dataset. e.g. exclude ID columns.\n",
    "2. Associate the prediction results with their corresponding input records.\n",
    "3. Filter the original or joined results before saving to S3. e.g. keep ID and probability columns only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the Sagemaker Model created during our training job to the Sagemaker Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb-2024-10-25-22-29-14\n",
      "arn:aws:sagemaker:us-east-1:002969758287:model/xgb-2024-10-25-22-29-14\n"
     ]
    }
   ],
   "source": [
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "\n",
    "model_name = \"xgb-2024-10-25-22-29-14\"\n",
    "print(model_name)\n",
    "\n",
    "\n",
    "info = sagemaker.describe_training_job(TrainingJobName=model_name)\n",
    "model_data = info[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "primary_container = {\"Image\": image, \"ModelDataUrl\": model_data}\n",
    "\n",
    "# Save our model to the Sagemaker Model Registry\n",
    "create_model_response = sagemaker.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=role, PrimaryContainer=primary_container\n",
    ")\n",
    "\n",
    "print(create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TrainingJobName': 'xgb-2024-10-25-22-29-14',\n",
       " 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:002969758287:training-job/xgb-2024-10-25-22-29-14',\n",
       " 'ModelArtifacts': {'S3ModelArtifacts': 's3://sagemaker-us-east-1-002969758287/DEMO-breast-cancer-prediction-xgboost-highlevel/output/xgb-2024-10-25-22-29-14/xgb-2024-10-25-22-29-14/output/model.tar.gz'},\n",
       " 'TrainingJobStatus': 'Completed',\n",
       " 'SecondaryStatus': 'Completed',\n",
       " 'HyperParameters': {'eta': '0.2',\n",
       "  'gamma': '4',\n",
       "  'max_depth': '5',\n",
       "  'min_child_weight': '6',\n",
       "  'num_round': '100',\n",
       "  'objective': 'binary:logistic',\n",
       "  'subsample': '0.8',\n",
       "  'verbosity': '0'},\n",
       " 'AlgorithmSpecification': {'TrainingImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.7-1',\n",
       "  'TrainingInputMode': 'File',\n",
       "  'MetricDefinitions': [{'Name': 'train:mae',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-mae:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:aucpr',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-aucpr:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:f1_binary',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-f1_binary:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:mae',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-mae:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:logloss',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-logloss:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:f1',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-f1:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:accuracy',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-accuracy:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:mse',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-mse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:recall',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-recall:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:poisson-nloglik',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-poisson-nloglik:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:precision',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-precision:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:error',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-error:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:ndcg',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-ndcg:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:map',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-map:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:f1_binary',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-f1_binary:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:auc',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-auc:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:auc',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-auc:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:error',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-error:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:poisson-nloglik',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-poisson-nloglik:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:rmse',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-rmse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:logloss',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-logloss:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:accuracy',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-accuracy:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:aucpr',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-aucpr:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:balanced_accuracy',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-balanced_accuracy:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:rmse',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-rmse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:mse',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-mse:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'validation:ndcg',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011validation-ndcg:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:f1',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-f1:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'},\n",
       "   {'Name': 'train:map',\n",
       "    'Regex': '.*\\\\[[0-9]+\\\\].*#011train-map:([-+]?[0-9]*\\\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'}],\n",
       "  'EnableSageMakerMetricsTimeSeries': False},\n",
       " 'RoleArn': 'arn:aws:iam::002969758287:role/LabRole',\n",
       " 'InputDataConfig': [{'ChannelName': 'train',\n",
       "   'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "     'S3Uri': 's3://sagemaker-us-east-1-002969758287/DEMO-breast-cancer-prediction-xgboost-highlevel/train',\n",
       "     'S3DataDistributionType': 'FullyReplicated'}},\n",
       "   'ContentType': 'text/csv',\n",
       "   'CompressionType': 'None',\n",
       "   'RecordWrapperType': 'None'},\n",
       "  {'ChannelName': 'validation',\n",
       "   'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "     'S3Uri': 's3://sagemaker-us-east-1-002969758287/DEMO-breast-cancer-prediction-xgboost-highlevel/validation',\n",
       "     'S3DataDistributionType': 'FullyReplicated'}},\n",
       "   'ContentType': 'text/csv',\n",
       "   'CompressionType': 'None',\n",
       "   'RecordWrapperType': 'None'}],\n",
       " 'OutputDataConfig': {'KmsKeyId': '',\n",
       "  'S3OutputPath': 's3://sagemaker-us-east-1-002969758287/DEMO-breast-cancer-prediction-xgboost-highlevel/output/xgb-2024-10-25-22-29-14',\n",
       "  'CompressionType': 'GZIP'},\n",
       " 'ResourceConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "  'InstanceCount': 1,\n",
       "  'VolumeSizeInGB': 50},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       " 'CreationTime': datetime.datetime(2024, 10, 25, 22, 29, 14, 771000, tzinfo=tzlocal()),\n",
       " 'TrainingStartTime': datetime.datetime(2024, 10, 25, 22, 29, 58, 881000, tzinfo=tzlocal()),\n",
       " 'TrainingEndTime': datetime.datetime(2024, 10, 25, 22, 31, 38, 428000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2024, 10, 25, 22, 31, 38, 605000, tzinfo=tzlocal()),\n",
       " 'SecondaryStatusTransitions': [{'Status': 'Starting',\n",
       "   'StartTime': datetime.datetime(2024, 10, 25, 22, 29, 14, 771000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2024, 10, 25, 22, 29, 58, 881000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Preparing the instances for training'},\n",
       "  {'Status': 'Downloading',\n",
       "   'StartTime': datetime.datetime(2024, 10, 25, 22, 29, 58, 881000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2024, 10, 25, 22, 31, 10, 112000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Downloading the training image'},\n",
       "  {'Status': 'Training',\n",
       "   'StartTime': datetime.datetime(2024, 10, 25, 22, 31, 10, 112000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2024, 10, 25, 22, 31, 25, 568000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Training image download completed. Training in progress.'},\n",
       "  {'Status': 'Uploading',\n",
       "   'StartTime': datetime.datetime(2024, 10, 25, 22, 31, 25, 568000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2024, 10, 25, 22, 31, 38, 428000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Uploading generated training model'},\n",
       "  {'Status': 'Completed',\n",
       "   'StartTime': datetime.datetime(2024, 10, 25, 22, 31, 38, 428000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2024, 10, 25, 22, 31, 38, 428000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Training job completed'}],\n",
       " 'FinalMetricDataList': [{'MetricName': 'validation:logloss',\n",
       "   'Value': 0.13369999825954437,\n",
       "   'Timestamp': datetime.datetime(2024, 10, 25, 22, 31, 22, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'train:logloss',\n",
       "   'Value': 0.06435000151395798,\n",
       "   'Timestamp': datetime.datetime(2024, 10, 25, 22, 31, 22, tzinfo=tzlocal())}],\n",
       " 'EnableNetworkIsolation': False,\n",
       " 'EnableInterContainerTrafficEncryption': False,\n",
       " 'EnableManagedSpotTraining': False,\n",
       " 'TrainingTimeInSeconds': 100,\n",
       " 'BillableTimeInSeconds': 100,\n",
       " 'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-002969758287/DEMO-breast-cancer-prediction-xgboost-highlevel/output/xgb-2024-10-25-22-29-14',\n",
       "  'CollectionConfigurations': []},\n",
       " 'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-002969758287/DEMO-breast-cancer-prediction-xgboost-highlevel/output/xgb-2024-10-25-22-29-14',\n",
       "  'ProfilingIntervalInMilliseconds': 500,\n",
       "  'DisableProfiler': False},\n",
       " 'ProfilingStatus': 'Enabled',\n",
       " 'ResponseMetadata': {'RequestId': '95230c91-9044-4d2f-a085-6b6748e91e07',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '95230c91-9044-4d2f-a085-6b6748e91e07',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '7401',\n",
       "   'date': 'Fri, 25 Oct 2024 23:10:54 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect Training Job Details\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created EndpointConfig: arn:aws:sagemaker:us-east-1:002969758287:endpoint-config/lab4-1-endpoint-config2024-10-25-23-11-05\n"
     ]
    }
   ],
   "source": [
    "# Create Endpoint Configuration\n",
    "\n",
    "\n",
    "# Create an endpoint config name. Here we create one based on the date  \n",
    "# so it we can search endpoints based on creation time.\n",
    "endpoint_config_name = 'lab4-1-endpoint-config' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())                            \n",
    "                            \n",
    "instance_type = 'ml.m5.xlarge'\n",
    "\n",
    "endpoint_config_response = sagemaker.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name, # You will specify this name in a CreateEndpoint request.\n",
    "    # List of ProductionVariant objects, one for each model that you want to host at this endpoint.\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\", # The name of the production variant.\n",
    "            \"ModelName\": model_name, \n",
    "            \"InstanceType\": instance_type, # Specify the compute instance type.\n",
    "            \"InitialInstanceCount\": 1 # Number of instances to launch initially.\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Created EndpointConfig: {endpoint_config_response['EndpointConfigArn']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deploy our model to real-time endpoint\n",
    "\n",
    "endpoint_name = 'lab4-1-endpoint' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())                            \n",
    "\n",
    "\n",
    "create_endpoint_response = sagemaker.create_endpoint(\n",
    "                                            EndpointName=endpoint_name, \n",
    "                                            EndpointConfigName=endpoint_config_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Job Status\n",
      "Endpoint still creating...\n",
      "Getting Job Status\n",
      "Endpoint still creating...\n",
      "Getting Job Status\n",
      "Endpoint still creating...\n",
      "Getting Job Status\n",
      "Endpoint in Service\n"
     ]
    }
   ],
   "source": [
    "# Wait for endpoint to spin up\n",
    "from time import sleep\n",
    "\n",
    "sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "while True:\n",
    "    print(\"Getting Job Status\")\n",
    "    res = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "    state = res[\"EndpointStatus\"]\n",
    "    \n",
    "    if state == \"InService\":\n",
    "        print(\"Endpoint in Service\")\n",
    "        break\n",
    "    elif state == \"Creating\":\n",
    "        print(\"Endpoint still creating...\")\n",
    "        sleep(60)\n",
    "    else:\n",
    "        print(\"Endpoint Creation Error - Check Sagemaker Console\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8843128085136414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Invoke Endpoint\n",
    "\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name=region)\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "                            EndpointName=endpoint_name,\n",
    "                            ContentType='text/csv',\n",
    "                            Body=data_batch_noID.to_csv(header=None, index=False).strip('\\n').split('\\n')[0]\n",
    "                            )\n",
    "print(response['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '50fed05c-f825-45c9-86a3-f0bba5d0913f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '50fed05c-f825-45c9-86a3-f0bba5d0913f',\n",
       "   'x-amzn-invoked-production-variant': 'variant1',\n",
       "   'date': 'Fri, 25 Oct 2024 23:17:41 GMT',\n",
       "   'content-type': 'text/csv; charset=utf-8',\n",
       "   'content-length': '19',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ContentType': 'text/csv; charset=utf-8',\n",
       " 'InvokedProductionVariant': 'variant1',\n",
       " 'Body': <botocore.response.StreamingBody at 0x7ff6eb379c90>}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine Response Body\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Assignment 4.1 \n",
    "\n",
    "Name: Ryan Laxamana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 1: Set Up Model Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelPackageGroup Arn : arn:aws:sagemaker:us-east-1:002969758287:model-package-group/breast-cancer-tumor-detection-1729898725\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import boto3\n",
    "from sagemaker import get_execution_role, Session\n",
    "\n",
    "# Set up session and client\n",
    "region = boto3.Session().region_name\n",
    "role = get_execution_role()\n",
    "sagemaker_session = Session(boto3.Session(region_name=region))\n",
    "sm_client = boto3.client('sagemaker', region_name=region)\n",
    "\n",
    "# Define the model package group name and description\n",
    "model_package_group_name = f\"breast-cancer-tumor-detection-{int(time.time())}\"\n",
    "model_package_group_input_dict = {\n",
    "    \"ModelPackageGroupName\": model_package_group_name,\n",
    "    \"ModelPackageGroupDescription\": \"Sample model package group for classifying tumors for breast cancer\",\n",
    "}\n",
    "\n",
    "# Create model package group in SageMaker Model Registry\n",
    "create_model_package_group_response = sm_client.create_model_package_group(\n",
    "    **model_package_group_input_dict\n",
    ")\n",
    "print(f\"ModelPackageGroup Arn : {create_model_package_group_response['ModelPackageGroupArn']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Set Up Model Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Package ARN: arn:aws:sagemaker:us-east-1:002969758287:model-package/breast-cancer-tumor-detection-1729898725/1\n",
      "Model Package Name: breast-cancer-tumor-detection-1729898725\n"
     ]
    }
   ],
   "source": [
    "# List model packages in a specific model package group\n",
    "model_package_group_name = 'breast-cancer-tumor-detection-1729898725'\n",
    "response = sm_client.list_model_packages(ModelPackageGroupName=model_package_group_name)\n",
    "\n",
    "# Print out model package details\n",
    "for package in response['ModelPackageSummaryList']:\n",
    "    print(\"Model Package ARN:\", package['ModelPackageArn'])\n",
    "    print(\"Model Package Name:\", package['ModelPackageGroupName'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelPackageGroupName': 'breast-cancer-tumor-detection-1729898725', 'ModelPackageVersion': 1, 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:002969758287:model-package/breast-cancer-tumor-detection-1729898725/1', 'ModelPackageDescription': 'Model to determine if a breast tumor is malignant or benign based on several medical characteristics', 'CreationTime': datetime.datetime(2024, 10, 26, 0, 7, 25, 759000, tzinfo=tzlocal()), 'InferenceSpecification': {'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.7-1', 'ImageDigest': 'sha256:b4a5f397d97c886f58dc45f9cae22d3479eb9dad7b06015844fdc745955df41c', 'ModelDataUrl': 's3://sagemaker-us-east-1-002969758287/DEMO-breast-cancer-prediction-xgboost-highlevel/output/xgb-2024-10-25-22-29-14/xgb-2024-10-25-22-29-14/output/model.tar.gz', 'Framework': 'XGBOOST', 'NearestModelName': 'Breast cancer prediction xgboost'}], 'SupportedRealtimeInferenceInstanceTypes': ['ml.t2.medium'], 'SupportedContentTypes': ['text/csv'], 'SupportedResponseMIMETypes': ['application/json']}, 'ModelPackageStatus': 'Completed', 'ModelPackageStatusDetails': {'ValidationStatuses': [], 'ImageScanStatuses': []}, 'CertifyForMarketplace': False, 'ModelApprovalStatus': 'Approved', 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:002969758287:user-profile/d-7qkd7avjswvj/RLaxamana', 'UserProfileName': 'RLaxamana', 'DomainId': 'd-7qkd7avjswvj', 'IamIdentity': {'Arn': 'arn:aws:sts::002969758287:assumed-role/LabRole/SageMaker', 'PrincipalId': 'AROAQBMIC5JH55EM2CYSS:SageMaker'}}, 'Domain': 'MACHINE_LEARNING', 'Task': 'CLASSIFICATION', 'SamplePayloadUrl': 's3://sagemaker-us-east-1-002969758287/DEMO-breast-cancer-prediction-xgboost-highlevel/batch/batch_data.csv', 'ResponseMetadata': {'RequestId': 'b1f7b410-0e53-488b-9c8f-7da878c2ddf1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'b1f7b410-0e53-488b-9c8f-7da878c2ddf1', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1634', 'date': 'Sat, 26 Oct 2024 00:17:13 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize SageMaker client\n",
    "sm_client = boto3.client('sagemaker', region_name='us-east-1')\n",
    "\n",
    "# Use the correct Model Package ARN\n",
    "model_package_arn = 'arn:aws:sagemaker:us-east-1:002969758287:model-package/breast-cancer-tumor-detection-1729898725/1'\n",
    "\n",
    "# Describe the model package using the ARN\n",
    "describe_response = sm_client.describe_model_package(ModelPackageName=model_package_arn)\n",
    "\n",
    "# Print the output\n",
    "print(describe_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 Write the Model Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelCardArn': 'arn:aws:sagemaker:us-east-1:002969758287:model-card/breast-cancer-tumor-detection-1729898725', 'ModelCardName': 'breast-cancer-tumor-detection-1729898725', 'ModelCardVersion': 1, 'Content': '{\"model_overview\":{\"model_name\":\"breast-cancer-tumor-detection-1729898725\",\"model_id\":\"breast-cancer-tumor-detection-1729898725 v1\",\"model_artifact\":[\"s3://sagemaker-us-east-1-002969758287/DEMO-breast-cancer-prediction-xgboost-highlevel/output/xgb-2024-10-25-22-29-14/xgb-2024-10-25-22-29-14/output/model.tar.gz\"],\"model_version\":1,\"problem_type\":\"Binary classification\",\"algorithm_type\":\"Linear regression\",\"model_description\":\"Model to determine if a breast tumor is malignant or benign based on several medical characteristics\",\"model_creator\":\"RLaxamana_AAI540\",\"model_owner\":\"RLaxamana\",\"inference_environment\":{\"container_image\":[\"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.7-1\"]}},\"intended_uses\":{\"intended_uses\":\"Classify breast tumors\"},\"training_details\":{\"objective_function\":{\"function\":{\"function\":\"Maximize\",\"facet\":\"Accuracy\",\"condition\":\"Fine tuning classification of tumor\"}},\"training_job_details\":{\"training_datasets\":[],\"training_environment\":{\"container_image\":[]},\"user_provided_training_metrics\":[],\"user_provided_hyper_parameters\":[]}}}', 'ModelCardStatus': 'PendingReview', 'CreationTime': datetime.datetime(2024, 10, 26, 0, 29, 25, 941000, tzinfo=tzlocal()), 'CreatedBy': {}, 'LastModifiedTime': datetime.datetime(2024, 10, 26, 0, 29, 25, 941000, tzinfo=tzlocal()), 'LastModifiedBy': {}, 'ResponseMetadata': {'RequestId': 'c56dc8b4-cbc2-4276-8df2-ddd5e334aeec', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'c56dc8b4-cbc2-4276-8df2-ddd5e334aeec', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1502', 'date': 'Sat, 26 Oct 2024 00:31:55 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SageMaker client\n",
    "client = boto3.client('sagemaker', region_name='us-east-1')  \n",
    "\n",
    "# Define Model Card Name and Version\n",
    "model_card_name = 'breast-cancer-tumor-detection-1729898725'\n",
    "model_card_version = 1\n",
    "\n",
    "# Describe the model card\n",
    "try:\n",
    "    response = client.describe_model_card(\n",
    "        ModelCardName=model_card_name,\n",
    "        ModelCardVersion=model_card_version\n",
    "    )\n",
    "    # Print the response\n",
    "    print(response)\n",
    "\n",
    "except client.exceptions.ResourceNotFoundException:\n",
    "    print(\"The specified model card or version does not exist.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/sagemaker_batch_transform|batch_transform_associate_predictions_with_input|Batch Transform - breast cancer prediction with high level SDK.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the License). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the license file accompanying this file. This file is distributed on an AS IS BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
